---
title: "[음성분석] 너의 소울을 들려줘: 랩 시뮬레이터"
order: 4
thumbnail: assets/img/thumbs/rap_simulator.png
tags: [ML, DL, Voice, Education, Transformer]
links:
  repo: https://github.com/YOUR/repo1
  report: /assets/docs/Rap_Simulator.pdf
---

# 🎤 랩 가수 음성 분석 및 유사 아티스트 추천 시스템
**개요**: 랩 가수의 특징을 학습하여 지망생에게 유사 아티스트를 추천해주는 '랩 시뮬레이터' 6인 팀 프로젝트

## 주요 성과
- Siamese 구조를 통해 래퍼 간 거리 기반 유사도 계산 모델 구현
  * 계층별 KFold(n_split=5) 결과 평균 검증 정확도 0.83, 평균 AUC 0.90으로 우수한 성과
- 설명 가능한 추천 시스템(XAI) 구현
  * 멜스펙트로그램을 활용한 톤, 템포, 리듬, 에너지 등 아티스트 특징 시각화
  * L2 거리 및 다차원 축소(t-SNE) 통한 거리 벡터 시각화
- 응용 가능성
  * AI 보컬 분석, 음악 추천, 음성 창작 지원 등 창작 도메인으로 확장 가능

## 역할
저는 음성 데이터 전처리, 모델링, 시각화를 담당하였습니다.

| 구분      | 내용                                                                                 |
| ------- | ---------------------------------------------------------------------------------- |
| **전처리** | 리샘플링(음질 정규화), 무음 제거, 길이 정규화, 유의미한 구간 추출, <br>
데이터 증강 시도(Pitch shift, Time stretch, GaussianNoise)                                 |
| **모델링** | 1️⃣ 사전 훈련된 트랜스포머 **HuBERT** 모델 임베딩<br>2️⃣ **Siamese Network** 기반 아티스트 유사도 계산 모델 구현 |
| **시각화** | **t-SNE**, **MFCC** 기반 샘플 분포 및 스펙트럼 분석                                               |


---

## 개요

랩 가수 지망생들이 독학이 아닌, 
랩은 언어, 리듬, 감정이 복합적으로 얽힌 예술 형식으로, 단순한 음성 인식 기술로는 표현의 개성을 포착하기 어렵습니다.
이 프로젝트는 음성 신호에서 스타일을 추출하기 위해 HuBERT 임베딩 모델을 사용하였고, 선행 연구를 참고해 **Siamese Network + Contrastive Loss** 구조를 활용했습니다.
하지만 해당 모델은 분류 정확도는 높았지만 아티스트 간 거리가 밀접해 서비스 목적에는 부합하지 않았습니다.
AudioClassification 모델을 사용함으로써 보다 정확한 아티스트 추천 시스템을 구축할 수 있었습니다.

그 결과, 단순한 분류가 아닌 각 랩가수의 고유한 **음성 스타일 임베딩 공간**을 구축하여,
지망생이 자신의 목소리로 녹음한 샘플을 업로드하면 **유사한 프로 래퍼를 추천**받는 모델을 완성했습니다.

---

### 상세 내용

1. **데이터 수집 및 전처리**
   * Jay-Z, Eminem, Snoop Dogg 등 주요 래퍼 음성 클립 수집 후 MR 제거.
   * Librosa를 이용해 비트 단위 구간 정규화 및 특징 벡터화(MFCC·Chroma·Tempo).
   * 녹음 품질·환경 편차 완화를 위해 데이터 증강을 적용하였으나, 오히려 분류 정확도가 하락해 증강 없이 진행.

2. **모델링**

   * Siamese Network로 구성된 **Contrastive Loss 기반 구조** 설계.

     * 동일 래퍼: 임베딩 거리 축소
     * 상이 래퍼: 거리 확장
     * 지망생 음성 입력 → 임베딩 추출 → 코사인 거리 계산 → Top-k 래퍼 추천

3. **모델 해석(XAI)**

   * 예: 지망생의 음성에서 “에너지 레벨↑ + 낮은 MFCC 대역”이 Eminem과 유사하다고 판단.

4. **결과 시각화**

   * t-SNE로 임베딩 공간 시각화: 래퍼별 클러스터링 확인.
   * 유사도 매트릭스 기반 Heatmap으로 스타일 관계를 한눈에 표현.

---

### 느낀 점

이 프로젝트를 통해 단순한 분류 정확도보다 **‘해석 가능한 감각적 이해’**가 얼마나 중요한지를 깨달았습니다.
샴 네트워크는 분류 정확도는 높았지만, 서비스 구현 측면에서 아티스트 간 차별성은 뚜렷하게 보여주지 못했습니다.
이에 HuBERT 임베딩 기반 AudioClassification 모델을 빌드하여 아티스트 유사성이 더욱 잘 보이도록 했습니다.

프로젝트 시간 제한과 인력 부족으로 음성 데이터 수집에는 세 명의 랩 가수만을 선정해 음원을 추출했습니다.
이들은 흑인과 백인 남성 랩 가수로, 차후에는 아시안 및 여성의 음성 데이터를 포함해 분석하면 모델 개선 여지가 있을 거라 생각합니다.

---

## 기술스택
Python(pandas, scikit-learn, pytorch)


## 링크
- 코드: [GitHub]({{ page.links.repo }})
- 보고서: [PDF]({{ page.links.report }})
